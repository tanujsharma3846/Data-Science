{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Science Masters - Hindi - 04 April 2023"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q1. Describe the decision tree classifier algorithm and how it works to make predictions.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The decision tree classifier is a supervised machine learning algorithm.\n",
    "- It is used for both binary and multiclass classifiction problems.\n",
    "- It is prone to overfitting if the tree is deep and complex.\n",
    "#\n",
    "- Working of a decison tree classifier.\n",
    "    - New data is classified by traversing the tree based on the values of its features.\n",
    "    - Starts at the root node and follows the path that matches the value of the feature(s) untill reaching a terminal node which represents the predicted class label."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is a step-by-step explanation of the mathematical intuition behind decision tree classification:\n",
    "#\n",
    "1. **Choose a splitting criterion**\n",
    "    - The first step in building a decision tree is to choose a splitting criterion.\n",
    "    - This is a measure of how well a particular feature separates the data into different classes.\n",
    "    - There are two common splitting criteria:\n",
    "        - **Entropy** measures the amount of uncertainty in a dataset. A dataset with high entropy is very uncertain, while a dataset with low entropy is very certain.\n",
    "        - **Gini impurity** measures the probability that a randomly chosen data point will be misclassified. A dataset with high gini impurity is very impure, while a dataset with low gini impurity is very pure.\n",
    "#\n",
    "2. **Split the data**\n",
    "    - Once a splitting criterion has been chosen, the data is split into two groups based on the value of the chosen feature.\n",
    "    - The algorithm then recursively repeats this process on each of the two groups, until each group contains only data points of a single class.\n",
    "#\n",
    "3. **Repeat until all groups are pure**\n",
    "    - The process of splitting the data continues until all groups are pure.\n",
    "    - This means that all data points in each group belong to the same class.\n",
    "#\n",
    "4. **Train the decision tree**\n",
    "    - Once the decision tree has been constructed, it is trained by assigning each leaf node to the class that is most common in that node.\n",
    "#\n",
    "5. **Make predictions**\n",
    "    - To make a prediction, the algorithm starts at the root node and follows the branches down the tree, making decisions based on the values of the features.\n",
    "    - The algorithm stops at a leaf node, and the class label of that leaf node is the predicted class for the data point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q3. Explain how a decision tree classifier can be used to solve a binary classification problem.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To solve a binary classification problem with a decision tree classifier, we first train the classifier on a dataset of labeled data. This dataset will contain data points with known class labels. The classifier, generally CART(Used Gini Impurity), will then use this data to learn how to make predictions.\n",
    "#\n",
    "- The classifier(CART) will do this by recursively splitting the data into smaller and smaller groups, until each group contains only data points of a single class. The classifier will then assign each leaf node to the class that is most common in that node.\n",
    "#\n",
    "- To make a prediction, the classifier will start at the root node and follow the branches down the tree, making decisions based on the values of the features. The classifier will stop at a leaf node, and the class label of that leaf node is the predicted class for the data point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Geometrically, decision trees can be thought of as a series of hyperplanes that divide the feature space into smaller and smaller regions.\n",
    "- The leaves of the tree represent the regions of the feature space that are associated with a particular class label.\n",
    "- By learning the decision rules from the training data, the decision tree algorithm can effectively separate the instances based on their feature values and can capture complex decision boundaries that may not be linear or axis-aligned."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- It is also known as an error matrix.\n",
    "- It is a performance measurement for machine learning classification problems where output can be two or more classes.\n",
    "- The confusion matrix shows the predicted values of the model in comparison to the actual values.\n",
    "- It is a four-way table that shows the following:\n",
    "    - **True Positives** (TP): The number of instances that were correctly classified as positive.\n",
    "    - **True Negatives** (TN): The number of instances that were correctly classified as negative.\n",
    "    - **False Positives** (FP): The number of instances that were incorrectly classified as positive.\n",
    "    - **False Negatives** (FN): The number of instances that were incorrectly classified as negative."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|| Actual +ve(1) | Actual -ve(0) |\n",
    "|--|--|--|\n",
    "| Predicted +ve(1) | True Positive (TP) | False Positive (FP) |\n",
    "| Predicted -ve(0) | False Negative (FN) | True Negative (TN) |\n",
    "#\n",
    "- The confusion matrix shows the predicted values of the model in comparison to the actual values.\n",
    "- The four values in the table are:\n",
    "    - **True Positives** (TP): The number of instances that were correctly classified as positive.\n",
    "    - **False Positives** (FP): The number of instances that were incorrectly classified as positive.\n",
    "    - **False Negatives** (FN): The number of instances that were incorrectly classified as negative.\n",
    "    - **True Negatives** (TN): The number of instances that were correctly classified as negative.\n",
    "#\n",
    "- Precision, recall, and F1 score can be calculated from the confusion matrix as follows:\n",
    "    - **Accuracy**\n",
    "        - It is the fraction of instances that were correctly classified.\n",
    "        - It is calculated as follows:\n",
    "    \n",
    "                accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "    #\n",
    "    - **Precision**\n",
    "        - It is the fraction of instances that were predicted as positive that were actually positive.\n",
    "        - It is calculated as follows:\n",
    "                \n",
    "                precision = TP / (TP + FP)\n",
    "    #\n",
    "    - **Recall**\n",
    "        - It is the fraction of instances that were actually positive that were predicted as positive.\n",
    "        - It is calculated as follows:\n",
    "\n",
    "                recall = TP / (TP + FN)\n",
    "    #\n",
    "    - **F1 score**\n",
    "        - It is a weighted harmonic mean of precision and recall.\n",
    "        - When False Positive(FP) and False Negative(FN) both are important.\n",
    "        - It is calculated as follows:\n",
    "\n",
    "                F1 Score = 2 * (precision * recall) / (precision + recall)\n",
    " #\n",
    " - Example\n",
    "\n",
    "|| Actual +ve(1) | Actual -ve(0) |\n",
    "|-|-|-|\n",
    "| Predicted +ve(1) |   85(TP)          |         15(FP) |\n",
    "| Predicted -ve(0) |   10(FN)          |          90(TN) |\n",
    "\n",
    "- **Precision**\n",
    "\n",
    "        precision = TP / (TP + FP)\n",
    "                  = 85 / (85 + 15)\n",
    "                  = 85 / 100 = 0.85\n",
    "\n",
    "- **Recall**\n",
    "\n",
    "        recall = TP / (TP + FN)\n",
    "               = 85 / (85 + 10)\n",
    "               = 85 / 95 = .89474\n",
    "- **F1 Score**\n",
    "\n",
    "        F1 Score = 2 * (precision * recall) / (precision + recall)\n",
    "                 = 2 * (0.85 * 0.89474) / (0.85 + .89474)\n",
    "                 = 2 * 0.760529 / 1.74474\n",
    "                 = 0.87180"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Choosing an appropriate evaluation metric for a classification problem is important because different metrics can emphasize different aspects of the model's performance.\n",
    "- Examples\n",
    "    - Accuracy is a good metric for evaluating a model's overall performance, but it can be misleading if the classes are imbalanced.\n",
    "    - Precision and recall are better metrics for evaluating a model's performance when the classes are imbalanced, but they can be misleading if the model is not able to distinguish between the classes well.\n",
    "$\n",
    "- To choose an evaluation metric, we need to condier:\n",
    "    - The purpose of the model.\n",
    "        - If the model is being used for making decisions, then accuracy may be the most important metric. If the model is being used for generating insights, then precision and recall may be more important.\n",
    "    - The cost of different types of errors.\n",
    "        - If a false positive is more costly than a false negative, then precision may be a more important metric. If a false negative is more costly than a false positive, then recall may be a more important metric.\n",
    "    - The nature of the data.\n",
    "        - If the data is imbalanced, then precision and recall may be more informative than accuracy.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q8. Provide an example of a classification problem where precision is the most important metric, and explain why.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is an example of a classification problem where precision is the most important metric:\n",
    "#\n",
    "- **Spam filtering**\n",
    "#\n",
    "- Here the goal is to classify emails as either spam or not spam.\n",
    "- A false positive in this case would be an email that is incorrectly classified as spam, while a false negative would be an email that is incorrectly classified as not spam.\n",
    "- In this case, it is more important to avoid false positives than false negatives. This is because a false positive can lead to a legitimate email being marked as spam and subsequently deleted. A false negative, on the other hand, will simply mean that a spam email is not caught, but this is less of a problem because spam emails can be easily ignored.\n",
    "- For this reason, precision is the most important metric for spam filtering.\n",
    "    - A high precision means that the model is very good at identifying spam emails, even if it sometimes misses some.\n",
    "    - A low precision means that the model is not very good at identifying spam emails, and it is likely to mark many legitimate emails as spam."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Q9. Provide an example of a classification problem where recall is the most important metric, and explain why.**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here is an example of a classification problem where recall is the most important metric:\n",
    "#\n",
    "- **Medical diagnosis**\n",
    "#\n",
    "- Here the goal is to classify patients as either having a disease or not having a disease. A false positive in this case would be a patient who is incorrectly classified as having a disease, while a false negative would be a patient who is incorrectly classified as not having a disease.\n",
    "- In this case it is more important to avoid false negatives than false positives. This is because a false negative can lead to a patient not receiving the treatment they need, which could have serious consequences. A false positive, on the other hand, will simply mean that a patient is unnecessarily treated, but this is less of a problem because most treatments are not harmful.\n",
    "#\n",
    "- For the above reason, recall is the most important metric for medical diagnosis.\n",
    "    - A high recall means that the model is very good at identifying patients who have a disease, even if it sometimes misses some.\n",
    "    - A low recall means that the model is not very good at identifying patients who have a disease, and it is likely to miss many patients who need treatment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
